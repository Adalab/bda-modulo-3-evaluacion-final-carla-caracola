{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Psss! README!\n",
    "# The purpose of this code is to explore the data from customer_flight_activity.csv and customer_loyalty_history.csv files. \n",
    "# Providing information for the user for decision making.\n",
    "# In adition, it performs the data transformation based on the conclusions from 01_exploration_conclusions.md.\n",
    "# The final output is a new file customer_data_transformed, where clean and trnasformed data from both csv is united."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Open data \n",
    "\n",
    "df_customer_flights = pd.read_csv(\"data/customer_flight_activity.csv\")\n",
    "df_customer_loyalty = pd.read_csv(\"data/customer_loyalty_history.csv\")\n",
    "dataframes_dict = {\"df_customer_flight✈️\" : df_customer_flights, \"df_customer_loyalty💞\" : df_customer_loyalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍️ Exploratory Data Analysis functions definition\n",
    "\n",
    "def explore_dataframes (df_dict):\n",
    "    \"\"\"\n",
    "    Explores and displays various statistics and details for each DataFrame in the provided dictionary.\n",
    "\n",
    "    Args:\n",
    "        df_dict (dict): A dictionary where the keys are DataFrame names (strings) and the values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with DataFrame names (with \"_duplicates\" suffix) as keys and DataFrames with duplicate rows as values.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df1 = pd.DataFrame({\n",
    "        ...     'A': [1, 2, 2, 4],\n",
    "        ...     'B': ['foo', 'bar', 'foo', 'baz']\n",
    "        ... })\n",
    "        >>> df2 = pd.DataFrame({\n",
    "        ...     'C': [10, 20, 30],\n",
    "        ...     'D': [1.1, None, 3.3]\n",
    "        ... })\n",
    "        >>> df_dict = {'df1': df1, 'df2': df2}\n",
    "        >>> duplicates = explore_dataframes(df_dict)\n",
    "        \n",
    "        Output:\n",
    "        Dataframe INFO:\n",
    "        FIRST FIVE (5) ROWS:\n",
    "        LAST FIVE (5) ROWS:\n",
    "        SAMPLE (5) ROWS:\n",
    "        DUPLICATES COUNT:\n",
    "        DATAFRAME WITH DUPLICATED ROWS (INCLUDING ALL APPEARANCES):\n",
    "        COUNT OF ROWS WITH ALL NULL VALUES IS:\n",
    "        COUNT OF COLUMNS WITH ALL NULL VALUES IS:\n",
    "        STATISTICAL METRICS FOR NUMERICAL COLUMNS:\n",
    "        STATISTICAL METRICS FOR CATEGORICAL COLUMNS:\n",
    "\n",
    "    Notes:\n",
    "        - The function prints information including the shape, first and last five rows, a sample of rows, duplicate counts, counts of rows and columns with all null values, and statistical metrics for numerical and categorical columns.\n",
    "        - If there are no categorical columns, it will print an error message.\n",
    "        - It returns a dictionary of DataFrames containing only duplicated rows, with the names of the DataFrames suffixed by \"_duplicates\".\n",
    "    \"\"\"\n",
    "    duplicate_dataframes_dict = {}\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        print(f\" \\n\\n----------- DATAFRAME NAME: {df_name} -----------\")\n",
    "        print(f\"\\n{df_name} ---> Dataframe INFO:\\n\")\n",
    "        display(df.info())\n",
    "        print(f\"\\n{df_name} ---> FIRST FIVE (5) ROWS:\")\n",
    "        display(df.head())\n",
    "        print(f\"\\n{df_name} ---> LAST FIVE (5) ROWS:\")\n",
    "        display(df.tail())\n",
    "        print(f\"\\n{df_name} ---> SAMPLE (5) ROWS:\")\n",
    "        display(df.sample(5))\n",
    "        print(f\" \\n{df_name} ---> DUPLICATES COUNT IS: {df.duplicated().sum()}, {round((df.duplicated().sum()/df.shape[0]*100),2)}% OVER TOTAL ROWS\\n\")\n",
    "        if df.duplicated().sum() > 0:\n",
    "            duplicates_df_name = name + \"_duplicates\"\n",
    "            duplicates_df = df[df.duplicated(keep=False)]\n",
    "            print(f\"{df_name} ---> DATAFRAME WITH DUPLICATED ROWS (INCLUDING ALL APPEARANCES):\\n\")\n",
    "            display(duplicates_df.head(10))\n",
    "            duplicate_dataframes_dict[duplicates_df_name] = duplicates_df\n",
    "        print(f\"\\n{df_name} --> COUNT OF ROWS WITH ALL NULL VALUES IS: {df.isnull().all(axis=1).sum()}\\n\")\n",
    "        print(f\"\\n{df_name} --> COUNT OF COLUMNS WITH ALL NULL VALUES IS: {df.isnull().all().sum()}\\n\")\n",
    "        print(F\"\\n{df_name} --> STATISTICAL METRICS FOR NUMERICAL COLUMNS:\")\n",
    "        display(df.describe().T)\n",
    "        try:\n",
    "            print(F\"\\n{df_name} --> STATISTICAL METRICS FOR CATEGORICAL COLUMNS:\")\n",
    "            display(df.describe(include=\"object\").T)\n",
    "        except:\n",
    "            print(\"\\nUPS... IT SEEMS LIKE THERE ARE NO COLUMNS WITH CATEGORICATL DATA\")\n",
    "    return duplicate_dataframes_dict\n",
    "\n",
    "def explore_columns (df_dict):\n",
    "    \"\"\"\n",
    "    Explores and displays detailed information about each column in the DataFrames provided in the dictionary.\n",
    "\n",
    "    Args:\n",
    "        df_dict (dict): A dictionary where the keys are DataFrame names (strings) and the values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        None: This function prints detailed column information for each DataFrame but does not return any value.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df1 = pd.DataFrame({\n",
    "        ...     'Age': [25, 30, 25, 40],\n",
    "        ...     'Gender': ['F', 'M', 'F', 'M']\n",
    "        ... })\n",
    "        >>> df2 = pd.DataFrame({\n",
    "        ...     'Salary': [50000, 60000, None],\n",
    "        ...     'Department': ['HR', 'Tech', 'Tech']\n",
    "        ... })\n",
    "        >>> explore_dataframe_columns({'df1': df1, 'df2': df2})\n",
    "        \n",
    "        Output:\n",
    "        UNIQUE VALUES:\n",
    "        VALUES COUNT:\n",
    "        COUNT OF DUPLICATES IN THE COLUMN:\n",
    "        COUNT OF NULL VALUES IN THE COLUMN:\n",
    "        STATISTICAL DESCRIPTION (NUMERIC):\n",
    "        STATISTICAL DESCRIPTION (CATEGORICAL):\n",
    "\n",
    "    Notes:\n",
    "        - The function prints unique values, value counts, counts of duplicates and null values, and statistical descriptions for each column.\n",
    "        - Numerical columns are described with statistics like mean, standard deviation, min, max, etc.\n",
    "        - Categorical columns are described with counts, unique values, top frequent values, and their frequencies.\n",
    "        - The function assumes that columns are either numerical or categorical and will handle each type accordingly.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        print(f\" \\n\\n----------- DATAFRAME NAME: {df_name} -----------\")\n",
    "        for index, column in enumerate(df.columns):\n",
    "            print (f\"\\n{index}) Column {column.upper()} (from {(df_name)} dataframe):\")\n",
    "            print (f\"\\n>>> UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "            print (f\"\\n>>> VALUES COUNT:\")\n",
    "            print (df[column].value_counts())\n",
    "            print (f\"\\n>>> COUNT OF DUPLICATES IN THE COLUMN:\")\n",
    "            print (df.duplicated(subset=[column]).sum())\n",
    "            print (f\"\\n>>> COUNT OF NULL VALUES IN THE COLUMN:\")\n",
    "            print (df[column].isnull().sum())\n",
    "            if df[column].dtype in ['int64', 'float64']:\n",
    "                print(\"\\nSTATISTICAL DESCRIPTION (NUMERIC):\")\n",
    "                display(df[column].describe())\n",
    "            else:\n",
    "                print(\"\\nSTATISTICAL DESCRIPTION (CATEGORICAL):\")\n",
    "                display(df[column].describe(include='object'))\n",
    "            print (\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶️ Exploratory Data Analysis code execution\n",
    "\n",
    "explore_dataframes(dataframes_dict)\n",
    "\n",
    "explore_columns(dataframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✍️ Data transformation (cleaning and union) functions definition\n",
    "\n",
    "def columns_to_snake_case (df_dict):\n",
    "    \"\"\"\n",
    "    Converts the column names of each DataFrame in a dictionary to snake_case format and prints the updated column names.\n",
    "\n",
    "    Args:\n",
    "        df_dict (dict): A dictionary where the keys are DataFrame names (strings) and the values are pandas DataFrames.\n",
    "\n",
    "    Returns:\n",
    "        None: This function modifies the DataFrames in place and prints the updated column names.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df1 = pd.DataFrame(columns=['First Name', 'Last Name'])\n",
    "        >>> df2 = pd.DataFrame(columns=['Date Of Birth', 'Email Address'])\n",
    "        >>> df_dict = {'df1': df1, 'df2': df2}\n",
    "        >>> columns_to_snake_case(df_dict)\n",
    "        \n",
    "        Output:\n",
    "        'DF1' ---> Dataframe COLUMNS:\n",
    "        Index(['first_name', 'last_name'], dtype='object')\n",
    "\n",
    "        'DF2' ---> Dataframe COLUMNS:\n",
    "        Index(['date_of_birth', 'email_address'], dtype='object')\n",
    "\n",
    "    Notes:\n",
    "        - The function assumes that the input dictionary contains pandas DataFrames.\n",
    "        - It will replace spaces with underscores and convert all characters to lowercase.\n",
    "        - The printed DataFrame names are uppercase with underscores replaced by spaces for readability.\n",
    "    \"\"\"\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        print(f\"\\n{df_name} ---> Dataframe COLUMNS:\\n\")\n",
    "        print(df.columns)\n",
    "\n",
    "def impute_nulls_as_special_category(df, column_list, category_name):\n",
    "    \"\"\"\n",
    "    Replaces null values in specified columns of a DataFrame with a given category name.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame in which null values need to be imputed.\n",
    "        column_list (list of str): A list of column names where null values should be replaced.\n",
    "        category_name (str): The category name used to replace null values.\n",
    "\n",
    "    Returns:\n",
    "        None: This function modifies the DataFrame in place and prints the status of the operation.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df = pd.DataFrame({\n",
    "        ...     'Name': ['Alice', None, 'Charlie'],\n",
    "        ...     'Age': [25, None, 30]\n",
    "        ... })\n",
    "        >>> impute_nulls_as_special_category(df, ['Name', 'Age'], 'Unknown')\n",
    "        \n",
    "        Output:\n",
    "        Null values imputed ✅ in column Name.\n",
    "        UNIQUE VALUES:\n",
    "        ['Alice' 'Unknown' 'Charlie']\n",
    "        \n",
    "        Null values imputed ✅ in column Age.\n",
    "        UNIQUE VALUES:\n",
    "        [25.  'Unknown' 30.]\n",
    "\n",
    "    Notes:\n",
    "        - The function will only replace null values in columns that exist in the DataFrame.\n",
    "        - If a column specified in `column_list` does not exist in the DataFrame, a warning message will be printed.\n",
    "    \"\"\"\n",
    "    # Iterate through the list of columns to replace nulls with \"category_name\"\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            # Replace nulls with the value \"category_name\" for each column in the list\n",
    "            df[column] = df[column].fillna(category_name)\n",
    "            print (f\"\\nNull values imputed ✅ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"❌ The column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "def transform_negative_values(df,column_list):\n",
    "    \"\"\"\n",
    "    Transforms negative values to positive values in specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame in which negative values need to be converted.\n",
    "        column_list (list of str): A list of column names where negative values should be transformed.\n",
    "\n",
    "    Returns:\n",
    "        None: This function modifies the DataFrame in place and prints the status of the operation.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df = pd.DataFrame({\n",
    "        ...     'Revenue': [-100, 200, -300],\n",
    "        ...     'Profit': [50, -75, -20]\n",
    "        ... })\n",
    "        >>> transform_negatives_to_positives(df, ['Revenue', 'Profit'])\n",
    "        \n",
    "        Output:\n",
    "        Negative values transformed ✅ in column Revenue.\n",
    "        UNIQUE VALUES:\n",
    "        [100 200 300]\n",
    "        \n",
    "        Negative values transformed ✅ in column Profit.\n",
    "        UNIQUE VALUES:\n",
    "        [ 50  75  20]\n",
    "\n",
    "    Notes:\n",
    "        - The function uses the absolute value function (`abs()`) to convert negative values to positive.\n",
    "        - If a column specified in `column_list` does not exist in the DataFrame, a warning message will be printed.\n",
    "    \"\"\"\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].abs()\n",
    "            print (f\"\\nNegative values transformed ✅ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"❌ The column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "def impute_nulls_as_median(df, column_list):\n",
    "    \"\"\"\n",
    "    Replaces null values in specified columns of a DataFrame with the median value of each column.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame in which null values need to be imputed.\n",
    "        column_list (list of str): A list of column names where null values should be replaced with the median.\n",
    "\n",
    "    Returns:\n",
    "        None: This function modifies the DataFrame in place and prints the status of the operation.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df = pd.DataFrame({\n",
    "        ...     'Age': [25, None, 30],\n",
    "        ...     'Salary': [50000, 60000, None]\n",
    "        ... })\n",
    "        >>> impute_nulls_as_median(df, ['Age', 'Salary'])\n",
    "        \n",
    "        Output:\n",
    "        Null values imputed ✅ in column Age.\n",
    "        UNIQUE VALUES:\n",
    "        [25.  27.5 30.]\n",
    "        \n",
    "        Null values imputed ✅ in column Salary.\n",
    "        UNIQUE VALUES:\n",
    "        [50000. 60000. 55000.]\n",
    "\n",
    "    Notes:\n",
    "        - The function computes the median of each column and uses it to replace null values.\n",
    "        - If a column specified in `column_list` does not exist in the DataFrame, a warning message will be printed.\n",
    "        - The median calculation ignores null values, so it's only based on the existing non-null values in the column.\n",
    "    \"\"\"\n",
    "    # Iterate through the list of columns to replace nulls with median\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            median= df[column].median()\n",
    "            # Replace nulls with the median for each column in the list\n",
    "            df[column] = df[column].fillna(median)\n",
    "            print (f\"\\nNull values imputed ✅ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"❌ The column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "def dfs_left_union (df_left, df_right):\n",
    "    \"\"\"\n",
    "    Performs a left join (union) between two DataFrames on a specified key and returns the resulting DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df_left (pandas.DataFrame): The left DataFrame to be joined.\n",
    "        df_right (pandas.DataFrame): The right DataFrame to be joined.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The resulting DataFrame after performing a left join on the key 'loyalty_number'.\n",
    "\n",
    "    Example:\n",
    "        >>> import pandas as pd\n",
    "        >>> df_customer_flights = pd.DataFrame({\n",
    "        ...     'loyalty_number': [1, 2, 3],\n",
    "        ...     'flight_number': ['AA123', 'BB456', 'CC789']\n",
    "        ... })\n",
    "        >>> df_customer_loyalty = pd.DataFrame({\n",
    "        ...     'loyalty_number': [1, 2],\n",
    "        ...     'customer_name': ['Alice', 'Bob']\n",
    "        ... })\n",
    "        >>> df_final = dfs_left_union(df_customer_flights, df_customer_loyalty)\n",
    "        \n",
    "        Output:\n",
    "        Dataframe on the left's SHAPE:(3, 2)\n",
    "        Dataframe on the right's SHAPE:(2, 2)\n",
    "        Dataframe were joined successfully ✅\n",
    "        Dataframe Final's SHAPE:(3, 3)\n",
    "        Dataframe Final's COLUMNS are:Index(['loyalty_number', 'flight_number', 'customer_name'], dtype='object')\n",
    "\n",
    "    Notes:\n",
    "        - The function performs a left join on the 'loyalty_number' column.\n",
    "        - If the 'loyalty_number' column is not present in both DataFrames, it will result in an error.\n",
    "        - Ensure that the column name 'loyalty_number' exists in both DataFrames before calling this function.\n",
    "    \"\"\"\n",
    "    print (f\"\\nDataframe on the left's SHAPE:{df_left.shape}\")\n",
    "    print (f\"\\nDataframe on the right's SHAPE:{df_right.shape}\")\n",
    "    df_final = df_customer_flights.merge(df_customer_loyalty, how='left', on='loyalty_number')\n",
    "    print(\"\\nDataframe were joined succesfully ✅\")\n",
    "    print (f\"\\nDataframe Final's SHAPE:{df_final.shape}\")\n",
    "    print (f\"\\nDataframe Final's COLUMNS are:{df_final.columns}\")\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶️ Data Transformation code execution\n",
    "\n",
    "# Rename columns to snake case format\n",
    "columns_to_snake_case(dataframes_dict)\n",
    "\n",
    "# Delete records from df customer_flights that are duplicated in all columns, keeping only the first appearance\n",
    "df_customer_flights.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"DUPLICATES COUNT IS: {df_customer_flights.duplicated().sum()}\")\n",
    "\n",
    "# In columns \"cancellation_year\" and \"cancelation_month\" replace NaN with \"Not Cancelled\"\n",
    "columns = [\"cancellation_year\",\"cancellation_month\"]\n",
    "category_name = \"Not Cancelled\"\n",
    "impute_nulls_as_special_category(df_customer_loyalty,columns,category_name)\n",
    "\n",
    "# In salary column transform negative value into positive and impute nulls assigning the median value\n",
    "columns = [\"salary\"]\n",
    "transform_negative_values(df_customer_loyalty,columns)\n",
    "impute_nulls_as_median(df_customer_loyalty, columns)\n",
    "\n",
    "# Join dataframes \n",
    "df_final = dfs_left_union(df_customer_flights,df_customer_loyalty)\n",
    "\n",
    "# Save data into a csv\n",
    "df_final.to_csv('data/customer_data_transformed1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loyalty number column analysis (unfinished)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of duplicates in loyalty_number column\n",
    "duplicates = df_customer_flights.duplicated(subset=['loyalty_number']).sum()\n",
    "print(f\"There are {duplicates} duplicates in the column 'loyalty_number', which represent {round((duplicates/df_customer_flights.shape[0]*100),2)}% over the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loyalty_number_duplicates = df_customer_flights[df_customer_flights.duplicated(subset=['loyalty_number'])]\n",
    "print (f\"\\n>>>DATAFRAME WITH DUPLICATED VALUES IN loyalty_number:\")\n",
    "display(df_loyalty_number_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The information in the dataframe is organized in a way that there is one row per each year and each month within a year. \n",
    "# Since there is info from 2 years it is expected to have 24 rows per loyalty_number (or less). So, I will only focus the analysis in those that appear more than 24 times\n",
    "# Calculate the times of appearance for each loyalty_number\n",
    "loyalty_number_value_counts = df_customer_flights['loyalty_number'].value_counts()\n",
    "print (f\"\\n>>> VALUES COUNT:\")\n",
    "print(loyalty_number_value_counts)\n",
    "# filter the Series to keep only the values that appear more than 24 times\n",
    "values_to_keep = loyalty_number_value_counts[loyalty_number_value_counts > 24].index\n",
    "print (f\"\\n>>> VALUES WITH MORE THAN 24 ROWS:\")\n",
    "print(values_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_customer_flights[df_customer_flights['loyalty_number'].isin(values_to_keep)].sort_values(by=['loyalty_number','year', 'month','total_flights'])\n",
    "filtered_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer_loyalty[df_customer_loyalty['loyalty_number'].isin(values_to_keep)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
