{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries \n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(os.path.abspath(os.path.join('..', 'src'))) \n",
    "\n",
    "\n",
    "# Configuration\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Exploration and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "    # create dataframes DONE\n",
    "    # at dataframe level \n",
    "        # print df name DONE\n",
    "        # visual exploration with .head(), .tail() and sample() DONE\n",
    "        # dataframe overview with .info() DONE\n",
    "        # check duplicates with .duplicated().sum DONE\n",
    "            # create separate dataframe with duplicates if needed DONE\n",
    "        # check null values .isnull().sum() DONE\n",
    "        # explore main statistical metrics for numerical and non numerical columns with .describe() and .describe(include = \"object\")\n",
    "    # at column level\n",
    "        # review columns names with .columns DONE\n",
    "        # review unique values with .unique() DONE\n",
    "        # review value count with .value_counts() DONE\n",
    "        # check null values with .isnull().sum() DONE\n",
    "        # atypical values\n",
    "    # create function/s for the EDA\n",
    "# Transformation\n",
    "# Dataframe union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Open data \n",
    "\n",
    "df_customer_flights = pd.read_csv(\"data/customer_flight_activity.csv\")\n",
    "df_customer_loyalty = pd.read_csv(\"data/customer_loyalty_history.csv\")\n",
    "dataframes_dict = {\"df_customer_flight‚úàÔ∏è\" : df_customer_flights, \"df_customer_loyaltyüíû\" : df_customer_loyalty}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Exploratory Data Analysis functions definition\n",
    "\n",
    "def explore_dataframes (df_dict):\n",
    "    \"\"\"\n",
    "    Provides relevant information for a Exploratory Data Analysis.\n",
    "    \n",
    "    This function receives a dict with dataframes and executes a series of \n",
    "    functions aiming to provide relevant information to analize the data.\n",
    "\n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    duplicate_dataframes_dict = {}\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        print(f\" \\n\\n----------- DATAFRAME NAME: {df_name} -----------\")\n",
    "        print(f\"\\n{df_name} ---> Dataframe INFO:\\n\")\n",
    "        display(df.info())\n",
    "        print(f\"\\n{df_name} ---> FIRST FIVE (5) ROWS:\")\n",
    "        display(df.head())\n",
    "        print(f\"\\n{df_name} ---> LAST FIVE (5) ROWS:\")\n",
    "        display(df.tail())\n",
    "        print(f\"\\n{df_name} ---> SAMPLE (5) ROWS:\")\n",
    "        display(df.sample(5))\n",
    "        print(f\" \\n{df_name} ---> DUPLICATES COUNT IS: {df.duplicated().sum()}, {round((df.duplicated().sum()/df.shape[0]*100),2)}% OVER TOTAL ROWS\\n\")\n",
    "        if df.duplicated().sum() > 0:\n",
    "            duplicates_df_name = name + \"_duplicates\"\n",
    "            duplicates_df = df[df.duplicated(keep=False)]\n",
    "            print(f\"{df_name} ---> DATAFRAME WITH DUPLICATED ROWS (INCLUDING ALL APPEARANCES):\\n\")\n",
    "            display(duplicates_df.head(10))\n",
    "            duplicate_dataframes_dict[duplicates_df_name] = duplicates_df\n",
    "        print(f\"\\n{df_name} --> COUNT OF ROWS WITH ALL NULL VALUES IS: {df.isnull().all(axis=1).sum()}\\n\")\n",
    "        print(f\"\\n{df_name} --> COUNT OF COLUMNS WITH ALL NULL VALUES IS: {df.isnull().all().sum()}\\n\")\n",
    "        print(F\"\\n{df_name} --> STATISTICAL METRICS FOR NUMERICAL COLUMNS:\")\n",
    "        display(df.describe().T)\n",
    "        try:\n",
    "            print(F\"\\n{df_name} --> STATISTICAL METRICS FOR CATEGORICAL COLUMNS:\")\n",
    "            display(df.describe(include=\"object\").T)\n",
    "        except:\n",
    "            print(\"\\nUPS... IT SEEMS LIKE THERE ARE NO COLUMNS WITH CATEGORICATL DATA\")\n",
    "    return duplicate_dataframes_dict\n",
    "\n",
    "def explore_columns (df_dict):\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        print(f\" \\n\\n----------- DATAFRAME NAME: {df_name} -----------\")\n",
    "        for index, column in enumerate(df.columns):\n",
    "            print (f\"\\n{index}) Column {column.upper()} (from {(df_name)} dataframe):\")\n",
    "            print (f\"\\n>>> UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "            print (f\"\\n>>> VALUES COUNT:\")\n",
    "            print (df[column].value_counts())\n",
    "            print (f\"\\n>>> COUNT OF DUPLICATES IN THE COLUMN:\")\n",
    "            print (df.duplicated(subset=[column]).sum())\n",
    "            print (f\"\\n>>> COUNT OF NULL VALUES IN THE COLUMN:\")\n",
    "            print (df[column].isnull().sum())\n",
    "            if df[column].dtype in ['int64', 'float64']:\n",
    "                print(\"\\nSTATISTICAL DESCRIPTION (NUMERIC):\")\n",
    "                display(df[column].describe())\n",
    "            else:\n",
    "                print(\"\\nSTATISTICAL DESCRIPTION (CATEGORICAL):\")\n",
    "                display(df[column].describe(include='object'))\n",
    "            print (\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'DF CUSTOMER FLIGHT‚úàÔ∏è' ---> Dataframe COLUMNS:\n",
      "\n",
      "Index(['loyalty_number', 'year', 'month', 'flights_booked',\n",
      "       'flights_with_companions', 'total_flights', 'distance',\n",
      "       'points_accumulated', 'points_redeemed', 'dollar_cost_points_redeemed'],\n",
      "      dtype='object')\n",
      "\n",
      "'DF CUSTOMER LOYALTYüíû' ---> Dataframe COLUMNS:\n",
      "\n",
      "Index(['loyalty_number', 'country', 'province', 'city', 'postal_code',\n",
      "       'gender', 'education', 'salary', 'marital_status', 'loyalty_card',\n",
      "       'clv', 'enrollment_type', 'enrollment_year', 'enrollment_month',\n",
      "       'cancellation_year', 'cancellation_month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# ‚ñ∂Ô∏è Exploratory Data Analysis code execution\n",
    "\n",
    "explore_dataframes(dataframes_dict)\n",
    "\n",
    "explore_columns(dataframes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úçÔ∏è Data transformation (cleaning and union) functions definition\n",
    "\n",
    "def columns_to_snake_case (df_dict):\n",
    "    for name, df in df_dict.items():\n",
    "        df_name = f\"'{name.upper().replace('_',' ')}'\"\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        print(f\"\\n{df_name} ---> Dataframe COLUMNS:\\n\")\n",
    "        print(df.columns)\n",
    "\n",
    "def impute_nulls_as_special_category(df, column_list, category_name):\n",
    "    # Iterate through the list of columns to replace nulls with \"Unknown\"\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            # Replace nulls with the value \"Unknown\" for each column in the list\n",
    "            df[column] = df[column].fillna(category_name)\n",
    "            print (f\"\\nNull values imputed ‚úÖ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"‚ùå The column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "def transform_negative_values(df,column_list):\n",
    "    \"\"\"Transform negative values into its absolute value\"\"\"\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].abs()\n",
    "            print (f\"\\nNegative values transformed ‚úÖ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"‚ùå The column '{column}' does not exist in the DataFrame.\")\n",
    "\n",
    "def impute_nulls_as_median(df, column_list):\n",
    "    # Iterate through the list of columns to replace nulls with median\n",
    "    for column in column_list:\n",
    "        if column in df.columns:\n",
    "            median= df[column].median()\n",
    "            # Replace nulls with the median for each column in the list\n",
    "            df[column] = df[column].fillna(median)\n",
    "            print (f\"\\nNull values imputed ‚úÖ in column {column}.\")\n",
    "            print (f\"UNIQUE VALUES:\")\n",
    "            print (df[column].unique())\n",
    "        else:\n",
    "            print(f\"‚ùå The column '{column}' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'DF CUSTOMER FLIGHT‚úàÔ∏è' ---> Dataframe COLUMNS:\n",
      "\n",
      "Index(['loyalty_number', 'year', 'month', 'flights_booked',\n",
      "       'flights_with_companions', 'total_flights', 'distance',\n",
      "       'points_accumulated', 'points_redeemed', 'dollar_cost_points_redeemed'],\n",
      "      dtype='object')\n",
      "\n",
      "'DF CUSTOMER LOYALTYüíû' ---> Dataframe COLUMNS:\n",
      "\n",
      "Index(['loyalty_number', 'country', 'province', 'city', 'postal_code',\n",
      "       'gender', 'education', 'salary', 'marital_status', 'loyalty_card',\n",
      "       'clv', 'enrollment_type', 'enrollment_year', 'enrollment_month',\n",
      "       'cancellation_year', 'cancellation_month'],\n",
      "      dtype='object')\n",
      "DUPLICATES COUNT IS: 0\n",
      "\n",
      "Null values imputed ‚úÖ in column cancellation_year.\n",
      "UNIQUE VALUES:\n",
      "['Not Cancelled' 2018.0 2015.0 2017.0 2014.0 2016.0 2013.0]\n",
      "\n",
      "Null values imputed ‚úÖ in column cancellation_month.\n",
      "UNIQUE VALUES:\n",
      "['Not Cancelled' 1.0 12.0 4.0 2.0 7.0 11.0 5.0 6.0 10.0 8.0 9.0 3.0]\n",
      "\n",
      "Negative values transformed ‚úÖ in column salary.\n",
      "UNIQUE VALUES:\n",
      "[ 83236.  73455. 103495. ...  76178.  91970.  57297.]\n",
      "\n",
      "Null values imputed ‚úÖ in column salary.\n",
      "UNIQUE VALUES:\n",
      "[ 83236.  73455. 103495. ...  76178.  91970.  57297.]\n",
      "\n",
      "Null values imputed ‚úÖ in column salary.\n",
      "UNIQUE VALUES:\n",
      "[ 83236.  73455. 103495. ...  76178.  91970.  57297.]\n"
     ]
    }
   ],
   "source": [
    "# ‚ñ∂Ô∏è Data Transformation code execution\n",
    "\n",
    "# Rename columns to snake case format\n",
    "columns_to_snake_case(dataframes_dict)\n",
    "\n",
    "# In df customer_flights, delete records that are duplicated in all columns keeping only the first appearance\n",
    "df_customer_flights.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"DUPLICATES COUNT IS: {df_customer_flights.duplicated().sum()}\")\n",
    "\n",
    "# In columns \"cancellation_year\" and \"cancelation_month\" replace NaN with \"Not Cancelled\"\n",
    "\n",
    "columns = [\"cancellation_year\",\"cancellation_month\"]\n",
    "category_name = \"Not Cancelled\"\n",
    "\n",
    "impute_nulls_as_special_category(df_customer_loyalty,columns,category_name)\n",
    "\n",
    "columns = [\"salary\"]\n",
    "transform_negative_values(df_customer_loyalty,columns)\n",
    "\n",
    "impute_nulls_as_median(df_customer_loyalty, columns)\n",
    "\n",
    "impute_nulls_as_median(df_customer_loyalty, columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loyalty number column analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 388887 duplicates in the column 'loyalty_number', which represent 95.87% over the total\n"
     ]
    }
   ],
   "source": [
    "def loyalty_number_analysis (df):\n",
    "    \n",
    "    # check the number of duplicates in loyalty_number column\n",
    "    duplicates = df_customer_flights.duplicated(subset=['loyalty_number']).sum()\n",
    "    print(f\"There are {duplicates} duplicates in the column 'loyalty_number', which represent {round((duplicates/df_customer_flights.shape[0]*100),2)}% over the total\")\n",
    "    \n",
    "    df_loyalty_number_duplicates = df_customer_flights[df_customer_flights.duplicated(subset=['loyalty_number'])]\n",
    "    print (f\"\\n>>>DATAFRAME WITH loyalty_number:\")\n",
    "    display(df_loyalty_number_duplicates)\n",
    "    # the information in the dataframe is organized in a way that there is one row per each year and each month within a year. \n",
    "    # Since there is info from 2 years it is expected to have 24 rows per loyalty_number (or less). So, I will only focus the analysis in those that appear more than 24 times\n",
    "    # Calculate the times of appearance for each loyalty_number\n",
    "    loyalty_number_value_counts = df_customer_flights['loyalty_number'].value_counts()\n",
    "    print (f\"\\n>>> VALUES COUNT:\")\n",
    "    print(loyalty_number_value_counts)\n",
    "    # filter the Series to keep only the values that appear more than 24 times\n",
    "    values_to_keep = loyalty_number_value_counts[loyalty_number_value_counts > 24].index\n",
    "    print (f\"\\n>>> VALUES WITH MORE THAN 24 ROWS:\")\n",
    "    print(values_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loyalty_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>flights_booked</th>\n",
       "      <th>flights_with_companions</th>\n",
       "      <th>total_flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>points_accumulated</th>\n",
       "      <th>points_redeemed</th>\n",
       "      <th>dollar_cost_points_redeemed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16942</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33843</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33844</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50744</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1460</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185796</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2384</td>\n",
       "      <td>238.0</td>\n",
       "      <td>488</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67646</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3318</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67645</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>2748</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84547</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84546</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>3015</td>\n",
       "      <td>301.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101447</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101448</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118349</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1586</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118348</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3893</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135250</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2316</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135249</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2569</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152150</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2191</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152151</th>\n",
       "      <td>101902</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2975</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loyalty_number  year  month  flights_booked  flights_with_companions  \\\n",
       "41              101902  2017      1               0                        0   \n",
       "42              101902  2017      1               0                        0   \n",
       "16942           101902  2017      2               0                        0   \n",
       "16943           101902  2017      2               0                        0   \n",
       "33843           101902  2017      3               0                        0   \n",
       "33844           101902  2017      3               0                        0   \n",
       "50744           101902  2017      4               4                        0   \n",
       "185796          101902  2017      4               4                        4   \n",
       "67646           101902  2017      5               7                        0   \n",
       "67645           101902  2017      5               9                        3   \n",
       "84547           101902  2017      6               9                        0   \n",
       "84546           101902  2017      6              10                        5   \n",
       "101447          101902  2017      7               0                        0   \n",
       "101448          101902  2017      7               0                        0   \n",
       "118349          101902  2017      8              13                        0   \n",
       "118348          101902  2017      8              17                        0   \n",
       "135250          101902  2017      9               3                        3   \n",
       "135249          101902  2017      9               7                        0   \n",
       "152150          101902  2017     10               7                        0   \n",
       "152151          101902  2017     10               5                        2   \n",
       "\n",
       "        total_flights  distance  points_accumulated  points_redeemed  \\\n",
       "41                  0         0                 0.0                0   \n",
       "42                  0         0                 0.0                0   \n",
       "16942               0         0                 0.0                0   \n",
       "16943               0         0                 0.0                0   \n",
       "33843               0         0                 0.0                0   \n",
       "33844               0         0                 0.0                0   \n",
       "50744               4      1460               146.0                0   \n",
       "185796              8      2384               238.0              488   \n",
       "67646               7      3318               331.0                0   \n",
       "67645              12      2748               274.0                0   \n",
       "84547               9      1521               152.0                0   \n",
       "84546              15      3015               301.0                0   \n",
       "101447              0         0                 0.0                0   \n",
       "101448              0         0                 0.0                0   \n",
       "118349             13      1586               158.0                0   \n",
       "118348             17      3893               389.0                0   \n",
       "135250              6      2316               231.0                0   \n",
       "135249              7      2569               256.0                0   \n",
       "152150              7      2191               219.0                0   \n",
       "152151              7      2975               297.0                0   \n",
       "\n",
       "        dollar_cost_points_redeemed  \n",
       "41                                0  \n",
       "42                                0  \n",
       "16942                             0  \n",
       "16943                             0  \n",
       "33843                             0  \n",
       "33844                             0  \n",
       "50744                             0  \n",
       "185796                           40  \n",
       "67646                             0  \n",
       "67645                             0  \n",
       "84547                             0  \n",
       "84546                             0  \n",
       "101447                            0  \n",
       "101448                            0  \n",
       "118349                            0  \n",
       "118348                            0  \n",
       "135250                            0  \n",
       "135249                            0  \n",
       "152150                            0  \n",
       "152151                            0  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df_customer_flights[df_customer_flights['loyalty_number'].isin(values_to_keep)].sort_values(by=['loyalty_number','year', 'month','total_flights'])\n",
    "filtered_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loyalty_number</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>salary</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>loyalty_card</th>\n",
       "      <th>clv</th>\n",
       "      <th>enrollment_type</th>\n",
       "      <th>enrollment_year</th>\n",
       "      <th>enrollment_month</th>\n",
       "      <th>cancellation_year</th>\n",
       "      <th>cancellation_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>193662</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Whitehorse</td>\n",
       "      <td>Y2K 6R0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>51124.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>3844.57</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>746226</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Whistler</td>\n",
       "      <td>V6T 1Y8</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>63501.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4089.04</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>279419</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>West Vancouver</td>\n",
       "      <td>V6V 8Z3</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>4117.37</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>354438</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>H2T 2J6</td>\n",
       "      <td>Male</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>4167.09</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>719633</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>V10 6T5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>52109.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>4250.78</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>411030</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>P1J 8T7</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>6503.14</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2017</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14263</th>\n",
       "      <td>732304</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Quebec City</td>\n",
       "      <td>G1B 3L5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>82727.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Nova</td>\n",
       "      <td>5715.79</td>\n",
       "      <td>2018 Promotion</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14579</th>\n",
       "      <td>243741</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V6E 3D9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>93595.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>7425.85</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>897772</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Quebec</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>H2Y 4R4</td>\n",
       "      <td>Male</td>\n",
       "      <td>High School or Below</td>\n",
       "      <td>44490.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>8123.96</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15744</th>\n",
       "      <td>373638</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Thunder Bay</td>\n",
       "      <td>K8T 5M5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>92501.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Star</td>\n",
       "      <td>11073.11</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       loyalty_number country          province            city postal_code  \\\n",
       "5              193662  Canada             Yukon      Whitehorse     Y2K 6R0   \n",
       "123            746226  Canada  British Columbia        Whistler     V6T 1Y8   \n",
       "141            279419  Canada  British Columbia  West Vancouver     V6V 8Z3   \n",
       "161            354438  Canada            Quebec        Montreal     H2T 2J6   \n",
       "204            719633  Canada  British Columbia        Victoria     V10 6T5   \n",
       "...               ...     ...               ...             ...         ...   \n",
       "14233          411030  Canada           Ontario         Toronto     P1J 8T7   \n",
       "14263          732304  Canada            Quebec     Quebec City     G1B 3L5   \n",
       "14579          243741  Canada  British Columbia       Vancouver     V6E 3D9   \n",
       "14937          897772  Canada            Quebec        Montreal     H2Y 4R4   \n",
       "15744          373638  Canada           Ontario     Thunder Bay     K8T 5M5   \n",
       "\n",
       "       gender             education   salary marital_status loyalty_card  \\\n",
       "5        Male              Bachelor  51124.0        Married         Star   \n",
       "123    Female              Bachelor  63501.0        Married         Star   \n",
       "141    Female               College      NaN         Single         Star   \n",
       "161      Male               College      NaN        Married         Star   \n",
       "204      Male              Bachelor  52109.0       Divorced         Star   \n",
       "...       ...                   ...      ...            ...          ...   \n",
       "14233  Female               College      NaN         Single         Star   \n",
       "14263    Male              Bachelor  82727.0        Married         Nova   \n",
       "14579  Female              Bachelor  93595.0        Married         Star   \n",
       "14937    Male  High School or Below  44490.0       Divorced         Star   \n",
       "15744  Female              Bachelor  92501.0       Divorced         Star   \n",
       "\n",
       "            clv enrollment_type  enrollment_year  enrollment_month  \\\n",
       "5       3844.57        Standard             2012                 5   \n",
       "123     4089.04        Standard             2018                 1   \n",
       "141     4117.37        Standard             2013                 7   \n",
       "161     4167.09        Standard             2018                 9   \n",
       "204     4250.78        Standard             2016                12   \n",
       "...         ...             ...              ...               ...   \n",
       "14233   6503.14        Standard             2017                 4   \n",
       "14263   5715.79  2018 Promotion             2018                 4   \n",
       "14579   7425.85        Standard             2013                 4   \n",
       "14937   8123.96        Standard             2012                 9   \n",
       "15744  11073.11        Standard             2014                10   \n",
       "\n",
       "       cancellation_year  cancellation_month  \n",
       "5                    NaN                 NaN  \n",
       "123                  NaN                 NaN  \n",
       "141                  NaN                 NaN  \n",
       "161                  NaN                 NaN  \n",
       "204                  NaN                 NaN  \n",
       "...                  ...                 ...  \n",
       "14233                NaN                 NaN  \n",
       "14263                NaN                 NaN  \n",
       "14579                NaN                 NaN  \n",
       "14937                NaN                 NaN  \n",
       "15744                NaN                 NaN  \n",
       "\n",
       "[163 rows x 16 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customer_loyalty[df_customer_loyalty['loyalty_number'].isin(values_to_keep)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
